{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box, Point, LineString\n",
    "import pyrosm\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy import stats\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import networkx as nx\n",
    "import math\n",
    "from rasterio.crs import CRS\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 50\n",
    "OUT_CRS = CRS.from_epsg(27700)  # https://epsg.io/27700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience function for printing\n",
    "def print_size(obj, suffix='B'):\n",
    "    num = getsizeof(obj)\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    print(\"%.1f%s%s\" % (num, 'Yi', suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "class Person():\n",
    "    def __init__(self, uid, household_uid, age, pos):\n",
    "        self.uid = uid\n",
    "        self.household_uid = household_uid\n",
    "        self.age = age\n",
    "        self.pos = pos\n",
    "    \n",
    "# households_gdf = pickle.loads(Path('pickles/london/households_gdf').read_bytes())\n",
    "people = pickle.loads(Path('../pickles/tower_hamlets/people_list').read_bytes())\n",
    "trimmed_work = pickle.loads(Path('../pickles/tower_hamlets/workplaces_gdf').read_bytes())\n",
    "boundary = pickle.loads(Path('../pickles/tower_hamlets/boundary').read_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_work = trimmed_work.to_crs(OUT_CRS)\n",
    "trimmed_work.plot(markersize=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get all public transport\n",
    "full_edges = pd.read_csv('../../data/uk_aggregate/Data_Release_v1.11/edges.csv')\n",
    "full_nodes = pd.read_csv('../../data/uk_aggregate/Data_Release_v1.11/nodes.csv')\n",
    "full_nodes = geopandas.GeoDataFrame(full_nodes, geometry=geopandas.points_from_xy(full_nodes.lon, full_nodes.lat), crs=\"EPSG:4326\")\n",
    "layers = pd.read_csv('../../data/uk_aggregate/Data_Release_v1.11/layers.csv')\n",
    "\n",
    "# Clip the nodes to the boundary\n",
    "nodes = geopandas.clip(full_nodes, boundary)\n",
    "nodes_set = set(nodes.set_index(['node', 'layer']).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get only the relevant time schedules\n",
    "from collections import namedtuple \n",
    "\n",
    "Ride = namedtuple('Ride', ['start_time', 'duration'])\n",
    "event_records = []\n",
    "\n",
    "with Path('../../data/uk_aggregate/Data_Release_v1.11/events.txt').open() as f:\n",
    "    for line in f:\n",
    "        eles = line.strip().split(',')\n",
    "        (ori_node, des_node, ori_layer, des_layer) = [int(ele.strip()) for ele in eles[:4]]\n",
    "        \n",
    "        if (not ((ori_node, ori_layer) in nodes_set and (des_node, des_layer) in nodes_set)):\n",
    "            continue\n",
    "        \n",
    "        iter_times = iter(eles[4:])\n",
    "        rides = [Ride(int(start_time), int(duration)) for (start_time, duration) in zip(iter_times, iter_times)]\n",
    "        \n",
    "        event_records.append((ori_node, des_node, ori_layer, des_layer, rides))\n",
    "\n",
    "events = pd.DataFrame.from_records(event_records, columns=['ori_node', 'des_node', 'ori_layer', 'des_layer', 'rides'])\n",
    "del event_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can't do anything with nodes that don't have schedules\n",
    "nodes_with_schedules = set(events.set_index(['ori_node', 'ori_layer']).index).union(events.set_index(['des_node', 'des_layer']).index)\n",
    "nodes_set = nodes_set.intersection(nodes_with_schedules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only select edges that start or end at the clipped nodes\n",
    "des_edges = full_edges[full_edges.set_index(['des_node', 'des_layer']).index.isin(nodes_set)]\n",
    "ori_edges = full_edges[full_edges.set_index(['ori_node', 'ori_layer']).index.isin(nodes_set)]\n",
    "unclipped_edges = des_edges.merge(ori_edges) # inner merge to get edges that start and end in the boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can't do anything with nodes that don't have edges\n",
    "nodes_with_edges = set(unclipped_edges.set_index(['ori_node', 'ori_layer']).index).union(unclipped_edges.set_index(['des_node', 'des_layer']).index)\n",
    "nodes_set = nodes_set.intersection(nodes_with_schedules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refilter nodes to remove ones without necessary information\n",
    "nodes = nodes[nodes.set_index(['node', 'layer']).index.isin(nodes_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Draw lines for the edges\n",
    "old_index = full_nodes.index\n",
    "full_nodes = full_nodes.set_index(['node', 'layer'])\n",
    "unclipped_edges = geopandas.GeoDataFrame(unclipped_edges, geometry=unclipped_edges.apply(lambda x: LineString([\n",
    "    full_nodes.loc[(x.ori_node, x.ori_layer)].geometry, \n",
    "    full_nodes.loc[(x.des_node, x.des_layer)].geometry\n",
    "]), axis=1))\n",
    "full_nodes = full_nodes.reset_index()\n",
    "full_nodes.index = old_index\n",
    "\n",
    "# commented for now as we require des AND ori nodes to be within the boundary instead of OR\n",
    "# Clip those edges to the boundary too\n",
    "# edges = geopandas.clip(unclipped_edges.reset_index(), boundary)  \n",
    "# Get rid of empty geometries\n",
    "#edges = edges[~edges.is_empty]\n",
    "edges = unclipped_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(17, 17))\n",
    "nodes.plot(ax=ax, markersize=1)\n",
    "edges.plot(ax=ax, linewidth=0.1)\n",
    "del fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes['osmid'] = nodes['node'].astype(str) + '_' + nodes['layer'].astype(str)\n",
    "nodes['x'] = nodes.geometry.x\n",
    "nodes['y'] = nodes.geometry.y\n",
    "nodes.set_index('osmid', verify_integrity=True, inplace=True, drop=False) # keep the column as osmnx needs it (as well as it being the index of the DF)\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges['u'] = edges['ori_node'].astype(str) + '_' + edges['ori_layer'].astype(str)\n",
    "edges['v'] = edges['des_node'].astype(str) + '_' + edges['des_layer'].astype(str)\n",
    "edges['key'] = edges.reset_index()['index']\n",
    "edges['osmid'] = edges['u'].astype(str) + '_' + edges['v'].astype(str)\n",
    "edges.set_index(['u', 'v', 'key'], inplace=True)\n",
    "edges = edges.set_crs(\"EPSG:4326\")\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx\n",
    "graph = osmnx.utils_graph.graph_from_gdfs(nodes, edges, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = osmnx.plot_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osmnx.utils_graph.graph_to_gdfs(graph, nodes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_node_ids = osmnx.utils_graph.graph_to_gdfs(graph, edges=False).osmid # the graph module removes some nodes (probably unconnected ones, TODO investigate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# transit_node_positions = [tuple(coord) for coord in nodes.to_crs(OUT_CRS)[['x', 'y']].to_numpy()]\n",
    "transit_node_positions = np.array(list(nodes.loc[graph_node_ids].to_crs(OUT_CRS).geometry.centroid.apply(lambda x: (x.x, x.y))))\n",
    "nodeKdTree = cKDTree(data=transit_node_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# amount = 10_000\n",
    "# print(f'For {amount} iterations')\n",
    "# for index, person in enumerate(people):\n",
    "#     if index > amount:\n",
    "#         break\n",
    "#     osmnx.distance.get_nearest_node(graph, person.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# print(f'For {len(people)} iterations')\n",
    "# for index, person in enumerate(people):\n",
    "#     nodeKdTree.query(x=person.pos, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by https://gis.stackexchange.com/a/301935\n",
    "def cKDQueryRadius(gdA_in, gdB_in, radius=300, reproject=True, p=2.0, workers=1):\n",
    "    gdA = gdA_in.copy()\n",
    "    gdB = gdB_in.copy()\n",
    "    if reproject:\n",
    "        in_crs = gdA.crs\n",
    "        gdA = gdA.to_crs(OUT_CRS)\n",
    "        gdB = gdB.to_crs(OUT_CRS)\n",
    "        \n",
    "    nA = np.array(list(gdA.geometry.centroid.apply(lambda x: (x.x, x.y))))\n",
    "    nB = np.array(list(gdB.geometry.centroid.apply(lambda x: (x.x, x.y))))\n",
    "    \n",
    "    btree = cKDTree(nB)\n",
    "    elements_in_radius = btree.query_ball_point(nA, r=radius, p=p, workers=workers)\n",
    "\n",
    "    gdf = pd.concat(\n",
    "        [gdA.reset_index(drop=True),\n",
    "        pd.Series(elements_in_radius, name='Elements in Radius')], axis=1\n",
    "    )\n",
    "    if reproject:\n",
    "        gdf = gdf.to_crs(gdA_in.crs)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# work_nearest_nodes = cKDQueryRadius(trimmed_work, nodes, radius=1_500, workers=5)\n",
    "# print_size(work_nearest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# nodes_nearest_households = cKDQueryRadius(nodes, households_gdf, radius=1_500, workers=5)\n",
    "# print_size(nodes_nearest_households)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# household_positions = list(households_gdf.geometry.centroid.apply(lambda x: (x.x, x.y)))\n",
    "# households_kd_tree = cKDTree(data=household_positions)\n",
    "# print_size(households_kd_tree) doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# workplace_positions = [(x, y) for x, y in zip(trimmed_work.geometry.x, trimmed_work.geometry.y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for pos in workplace_positions:\n",
    "#     households_kd_tree.query_ball_point(pos, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# households_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Remove when Person pickle is remade for South London\n",
    "# for person in people:\n",
    "#     person.pos = (person.pos.x, person.pos.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df = pd.DataFrame(data=[{'uid': person.uid, 'x': person.pos[0], 'y': person.pos[1], 'age': person.age} for person in people])\n",
    "print_size(people_df)\n",
    "del people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# people_gdf = geopandas.GeoDataFrame(people_df, geometry=geopandas.points_from_xy(people_df.x, people_df.y), crs=OUT_CRS)\n",
    "# fig, ax = plt.subplots(figsize=(10,10))\n",
    "# people_gdf.plot(ax=ax, marker_size=0.1)\n",
    "# del fig, ax, test, people_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_boundary = boundary.copy()\n",
    "projected_boundary = projected_boundary.set_crs(\"EPSG:4326\")\n",
    "projected_boundary = projected_boundary.to_crs(OUT_CRS)\n",
    "bounds = projected_boundary.bounds\n",
    "boundary_minx = bounds.loc[bounds.index[0], 'minx']\n",
    "boundary_maxx = bounds.loc[bounds.index[0], 'maxx']\n",
    "boundary_miny = bounds.loc[bounds.index[0], 'miny']\n",
    "boundary_maxy = bounds.loc[bounds.index[0], 'maxy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_size = 250 # meters for OUT_CRS\n",
    "y_len = int(math.ceil((boundary_maxy - boundary_miny) / bucket_size))\n",
    "x_len = int(math.ceil((boundary_maxx - boundary_minx) / bucket_size))\n",
    "\n",
    "print(f'y: {y_len}, x: {x_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployed = people_df.loc[(17 <= people_df['age']) & (people_df['age'] <= 67)].copy()\n",
    "print(len(unemployed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployed['bucket_x'] = np.ceil(((unemployed['x'] - boundary_minx) / bucket_size)).astype(int) - 1\n",
    "unemployed['bucket_y'] = np.ceil(y_len - ((unemployed['y'] - boundary_miny) / bucket_size)).astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unemployed_bucket = np.array([[]] * (y_len * x_len) + [[1]], dtype=object)[:-1].reshape((y_len, x_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_buckets():\n",
    "    unemployed_bucket = [[[] for x in range(x_len)] for y in range(y_len)]\n",
    "    for person in unemployed.itertuples():\n",
    "        unemployed_bucket[person.bucket_y][person.bucket_x].append(person.uid)\n",
    "    \n",
    "    return unemployed_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "unemployed_bucket = make_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unemployed_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/44865023/how-can-i-create-a-circular-mask-for-a-numpy-array\n",
    "def create_circular_mask(h, w, centre_y=None, centre_x=None, radius=None):\n",
    "    if centre_x is None: # use the middle of the image\n",
    "        centre_x = int(w / 2)\n",
    "    if centre_y is None:\n",
    "        centre_y = int(h / 2)\n",
    "    if radius is None: # use the smallest distance between the center and image walls\n",
    "        radius = min(centre_y, centre_x, (w - centre_x), (h - centre_y))\n",
    "\n",
    "    y, x = np.ogrid[-centre_y:(h - centre_y), -centre_x:(w - centre_x)]\n",
    "    mask = (x * x) + (y * y) <= (radius * radius)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "counts = np.array([list(map(len, row)) for row in unemployed_bucket])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mask = create_circular_mask(h=y_len, w=x_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere(mask)\n",
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "probabilities = counts[mask] / np.sum(counts[mask])\n",
    "probabilities.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "chosen_buckets = np.random.choice(np.arange(indices.shape[0]), 1_000, p=probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check the sampling matches the underlying probabilities\n",
    "chosen_buckets = np.random.choice(np.arange(indices.shape[0]), 50_000, p=probabilities)\n",
    "\n",
    "test = np.zeros(counts.shape)\n",
    "for index, chosen in enumerate(chosen_buckets):\n",
    "    test[tuple(indices[chosen])] += 1\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.imshow(test, origin='lower', vmax=10)\n",
    "del fig, ax, test, chosen_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoViablePeopleError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_unemployed_within_dist(y, x, dist, cache_size=200):\n",
    "    counts = np.array([list(map(len, row)) for row in unemployed_bucket])\n",
    "    y = y_len - int(math.ceil((y - boundary_miny) / bucket_size)) - 1\n",
    "    x = int(math.ceil((x - boundary_minx) / bucket_size)) - 1\n",
    "    dist = dist / bucket_size\n",
    "    mask = create_circular_mask(h=y_len, w=x_len, centre_y=y, centre_x=x, radius=dist)\n",
    "    \n",
    "    indices = np.argwhere(mask)\n",
    "    if np.sum(counts[mask]) == 0:\n",
    "        raise NoViablePeopleError(f'No viable unemployed people left around (x:{x}, y:{y})')\n",
    "    probabilities = counts[mask] / np.sum(counts[mask])\n",
    "#     print(f'x: {x}, y: {y}, indices: {indices}, probabilities: {probabilities}')\n",
    "    \n",
    "    chosen_buckets = np.random.choice(np.arange(indices.shape[0]), cache_size, p=probabilities) # a cache of sampled choices\n",
    "    chosen_iter = iter(chosen_buckets)\n",
    "    failures = 0\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            next_bucket_pos = tuple(indices[next(chosen_iter)])\n",
    "        except StopIteration: # used up the cache, repopulate with some more random choices\n",
    "            chosen_buckets = np.random.choice(np.arange(indices.shape[0]), cache_size, p=probabilities)\n",
    "            chosen_iter = iter(chosen_buckets)\n",
    "            continue\n",
    "        try: \n",
    "            next_person = unemployed_bucket[next_bucket_pos[0]][next_bucket_pos[1]].pop()\n",
    "        except IndexError: # no unemployed people in that bucket\n",
    "            failures += 1\n",
    "            if failures > 300: # we had a lot of failures, recalc the probability map\n",
    "                failures = 0\n",
    "                \n",
    "                counts = np.array([list(map(len, row)) for row in unemployed_bucket])\n",
    "                \n",
    "                total_unemployed_left = np.sum(counts[mask])\n",
    "                if total_unemployed_left == 0:\n",
    "                    raise NoViablePeopleError(f'No viable unemployed people left around ({x}, {y})')\n",
    "                \n",
    "                probabilities = counts[mask] / total_unemployed_left\n",
    "                \n",
    "                chosen_buckets = np.random.choice(np.arange(indices.shape[0]), cache_size, p=probabilities)\n",
    "                chosen_iter = iter(chosen_buckets)\n",
    "            continue\n",
    "            \n",
    "        yield next_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployed_bucket = make_buckets()\n",
    "\n",
    "# pick a random workplace to query around\n",
    "rand_workplace = trimmed_work.loc[[len(trimmed_work) // 3]]\n",
    "\n",
    "(y, x) = (rand_workplace.geometry.y, rand_workplace.geometry.x)\n",
    "# (y, x) = (397000, 385000)\n",
    "print(f'({float(x)}, {float(y)})')\n",
    "valid_unemployed_gen_5k = valid_unemployed_within_dist(y, x, 3_000)\n",
    "\n",
    "# sanity check the sampling matches the underlying probabilities\n",
    "chosen_people = [(next(valid_unemployed_gen_5k)) for i in range(45_000)]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(15, 15))\n",
    "ax1.set_aspect('equal')\n",
    "ax2.set_aspect('equal')\n",
    "# sanity check\n",
    "chosen = people_df.loc[chosen_people]\n",
    "chosen.plot(ax=ax1, x='x', y='y', kind='scatter', s=0.1)\n",
    "(xmin, xmax, ymin, ymax) = (chosen['x'].min(), chosen['x'].max(), chosen['y'].min(), chosen['y'].max())\n",
    "people_df[(people_df['x'] > xmin) & (people_df['x'] < xmax) & (people_df['y'] > ymin) & (people_df['y'] < ymax)].plot(ax=ax2, x='x', y='y', kind='scatter', s=0.1)\n",
    "\n",
    "ax1.plot(x, y, 'r+')\n",
    "ax2.plot(x, y, 'r+')\n",
    "# rand_workplace.plot(ax=ax1, markersize=100, c='red', marker='x')\n",
    "# rand_workplace.plot(ax=ax2, markersize=100, c='red', marker='x')\n",
    "del fig, ax1, ax2, chosen_people, chosen, xmin, ymin, xmax, ymax, rand_workplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployed_bucket = make_buckets()\n",
    "valid_unemployed_gen_5k = valid_unemployed_within_dist(y, x, 5_000)\n",
    "%timeit -r 10 -n 15_000 next(valid_unemployed_gen_5k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del valid_unemployed_gen_5k, y, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# households within 60k\n",
    "# generate a probability heatmap\n",
    "# ravel and sample it\n",
    "# if there are no free slots set it to 0\n",
    "# if 100 misses in a row, regenerate probability map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a random vector\n",
    "# query-ball around that vector\n",
    "# try X vectors, then new dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# uses about 5-6GB of memory for Manchester with 4400 nodes and 6200 edges \n",
    "# about 12-14GB of mem for London with 7000 nodes 16000 edges\n",
    "travel_times = dict(nx.all_pairs_dijkstra_path_length(graph, cutoff=90, weight='minutes'))  # {node(str): {target(str): dist(num)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "Path('../pickles/london/travel_times').write_bytes(pickle.dumps(travel_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "MIN_TRAVEL_TIME = 15\n",
    "graph_node_ids_to_index = {node_id: index for index, node_id in enumerate(list(graph_node_ids))}\n",
    "\n",
    "transit_nodes_to_commuting_nodes = {graph_node_ids_to_index[src_node_id]: [target_node_id for target_node_id, time in times_dict.items() if time > MIN_TRAVEL_TIME] \n",
    "                   for src_node_id, times_dict in travel_times.items()}\n",
    "\n",
    "def get_transit_nodes_to_commuting_nodes():\n",
    "    return deepcopy(transit_nodes_to_commuting_nodes)\n",
    "    \n",
    "del travel_times, graph_node_ids_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoNearbyTransitNodesError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearby_transit_nodes(workplace):\n",
    "    dist = 1_000\n",
    "    nearby_transit_nodes = nodeKdTree.query_ball_point((workplace.geometry.x, workplace.geometry.y), dist)\n",
    "    while len(nearby_transit_nodes) == 0 and dist <= 5_000:\n",
    "        dist += 1000\n",
    "        nearby_transit_nodes = nodeKdTree.query_ball_point((workplace.geometry.x, workplace.geometry.y), dist)\n",
    "    if len(nearby_transit_nodes) == 0:\n",
    "        raise NoNearbyTransitNodesError(f\"No transit nodes were found within walking distance of workplace {workplace.index}\")\n",
    "    \n",
    "    return nearby_transit_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_to_radius_search = dict(zip(list(graph_node_ids), list(map(lambda pos: valid_unemployed_within_dist(pos[1], pos[0], 5_000, 100), transit_node_positions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class TransportType(Enum):\n",
    "    PUBLIC_TRANSIT = 0,\n",
    "    DRIVING = 1,\n",
    "    CYCLING = 2,\n",
    "    WALKING = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "to_allocate = len(unemployed)\n",
    "print(f'Trying to allocate {to_allocate} people, {len(trimmed_work)} workplaces')\n",
    "\n",
    "unemployed_bucket = make_buckets()\n",
    "reachable_nodes = get_transit_nodes_to_commuting_nodes()\n",
    "\n",
    "people_to_workplaces = [None] * len(people_df)\n",
    "people_to_transport_type = [None] * len(people_df)\n",
    "\n",
    "failures = 0\n",
    "successes = 0\n",
    "workplace_indices = []\n",
    "\n",
    "for index, workplace in enumerate(trimmed_work.sample(frac=1).itertuples()): # iterate over shuffled workplaces\n",
    "    if successes >= to_allocate:\n",
    "        print(f'Allocated all people after {index} workplaces')\n",
    "        break\n",
    "    if index < 9:\n",
    "        workplace_indices.append(workplace.index)\n",
    "        \n",
    "    transport_options = [TransportType.PUBLIC_TRANSIT, TransportType.DRIVING, TransportType.CYCLING, TransportType.WALKING]\n",
    "    \n",
    "    try:\n",
    "        nearby_transit_nodes = get_nearby_transit_nodes(workplace)\n",
    "    except NoNearbyTransitNodesError:\n",
    "        transport_options.remove(TransportType.PUBLIC_TRANSIT)\n",
    "        \n",
    "    valid_unemployed_gen_60k = valid_unemployed_within_dist(workplace.geometry.y, workplace.geometry.x, 60_000)\n",
    "    valid_unemployed_gen_20k = valid_unemployed_within_dist(workplace.geometry.y, workplace.geometry.x, 20_000)\n",
    "    valid_unemployed_gen_5k = valid_unemployed_within_dist(workplace.geometry.y, workplace.geometry.x, 5_000)\n",
    "    \n",
    "    for _ in range(workplace.capacity):\n",
    "        # TODO update to better reflect real distributions if possible, maybe weight it by workplace size, more likely to walk if you own the business\n",
    "        random.shuffle(transport_options)\n",
    "        random_transport = iter(transport_options)\n",
    "        \n",
    "        person_id = None\n",
    "        transport_type = None\n",
    "        \n",
    "        while (person_id == None):\n",
    "            try:\n",
    "                transport_type = next(random_transport)\n",
    "            except StopIteration:\n",
    "                break\n",
    "            \n",
    "            if transport_type == TransportType.PUBLIC_TRANSIT:\n",
    "                source_node_index = np.random.choice(nearby_transit_nodes)\n",
    "                try:\n",
    "                    while (person_id == None):\n",
    "                        dest_osmid = random.choice(reachable_nodes[source_node_index])\n",
    "                        try:\n",
    "                            person_id = next(nodes_to_radius_search[dest_osmid])\n",
    "                        except StopIteration:\n",
    "                            reachable_nodes[source_node_index].remove(dest_osmid)\n",
    "                except (NoViablePeopleError, IndexError):\n",
    "                    transport_options.remove(transport_type)\n",
    "            elif transport_type == TransportType.DRIVING:\n",
    "                try:\n",
    "                    person_id = next(valid_unemployed_gen_60k)\n",
    "                except NoViablePeopleError:\n",
    "                    transport_options.remove(transport_type)\n",
    "            elif transport_type == TransportType.CYCLING:\n",
    "                try:\n",
    "                    person_id = next(valid_unemployed_gen_20k)\n",
    "                except NoViablePeopleError:\n",
    "                    transport_options.remove(transport_type)\n",
    "            elif transport_type == TransportType.WALKING:\n",
    "                try:\n",
    "                    person_id = next(valid_unemployed_gen_5k)\n",
    "                except NoViablePeopleError:\n",
    "                    transport_options.remove(transport_type)\n",
    "        \n",
    "        if person_id:\n",
    "            if transport_type:\n",
    "                people_to_transport_type[person_id] = transport_type\n",
    "            \n",
    "            people_to_workplaces[person_id] = workplace.index\n",
    "            successes += 1\n",
    "            if successes >= to_allocate:\n",
    "                break\n",
    "        else:\n",
    "            failures +=1\n",
    "            continue            \n",
    "    \n",
    "    # workplace_row.capacity\n",
    "    # workplace.index    \n",
    "    \n",
    "print(f'Successes: {successes}, Failures: {failures}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "workplaces_to_people = defaultdict(list)\n",
    "for person_id, workplace_index in enumerate(people_to_workplaces):\n",
    "    if workplace_index is not None:\n",
    "        workplaces_to_people[workplace_index].append(person_id)\n",
    "\n",
    "example_workplaces_to_people = {ind: workplaces_to_people[ind] for ind in workplace_indices}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "ax.set_aspect('equal')\n",
    "marker_styles = [\n",
    "                ('red', 'o'), ('blue', 'o'), ('green', 'o'),\n",
    "                ('red', 'P'), ('blue', 'P'), ('green', 'P'),\n",
    "                ('red', '*'), ('blue', '*'), ('green', '*')\n",
    "                ]\n",
    "\n",
    "for (workplace_index, worker_indices), (color, marker) in zip(example_workplaces_to_people.items(), marker_styles):\n",
    "    trimmed_work.iloc[[workplace_index]].plot(ax=ax, markersize=100, c=color, marker=marker)\n",
    "    workers = people_df.iloc[worker_indices]\n",
    "    workers.plot(ax=ax, x='x', y='y', kind='scatter', s=30, c=color, marker=marker)\n",
    "del fig, ax, workplaces_to_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
