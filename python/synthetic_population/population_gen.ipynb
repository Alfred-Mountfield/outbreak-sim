{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Module Requirements do a pip install although rasterio and similar are a massive pain on Windows so WSL is advised, or respective libraries in a Conda env\n",
    "rasterio, rioxarray, geopandas, pyrosm, matplotlib, pandas, numpy, scipy, shapely, osmnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum\n",
    "from typing import Tuple\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import math\n",
    "\n",
    "import pyrosm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas\n",
    "import rasterio\n",
    "import rioxarray as rxr\n",
    "import osmnx\n",
    "from shapely.geometry import mapping, box, LineString\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from rasterio.crs import CRS\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be picked appropriately for the boundary area to avoid distortion, this example is in the UK so using 27700\n",
    "OUT_CRS = CRS.from_epsg(27700)  # https://epsg.io/27700 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Acquire Boundary and Data from OpenStreetMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get OpenStreetMap data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Protobuf data 'greater-london-latest.osm.pbf' (65.41 MB) to:\n",
      "'/tmp/pyrosm/greater-london-latest.osm.pbf'\n"
     ]
    }
   ],
   "source": [
    "fp = pyrosm.get_data(\"Greater London\", update=True)\n",
    "osm = pyrosm.OSM(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all boundaries using the default settings\n",
    "# boundaries = osm.get_boundaries()\n",
    "# boundaries.head(3) # left as an example to see possible Boundary choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boundary = osm.get_boundaries(name=\"London Borough of Tower Hamlets\")\n",
    "\n",
    "# bbox = box(-0.04, 51.48, 0.011, 51.52)  # a random box around a part of Tower Hamlets and Canary Wharf\n",
    "# bbox = box(-0.161,51.449,-0.002,51.529)  # a random box containing City of London and some of South London like Brixton\n",
    "bbox = box(-0.417548,51.370878,0.144128,51.602621) # bigger box of London\n",
    "# bbox = box(-2.387604,53.398281,-2.112259,53.55031)  # Greater Manchester\n",
    "boundary = geopandas.GeoDataFrame({'geometry': bbox}, index=[0], crs=\"EPSG:4326\")\n",
    "\n",
    "# # Get the shapely geometry from GeoDataFrame\n",
    "bbox_geom = boundary['geometry'].values[0]\n",
    "# Initialise with bounding box\n",
    "osm = pyrosm.OSM(fp, bounding_box=bbox_geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get all residential buildings as well as ones without a specific tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 35s, sys: 1min, total: 3min 36s\n",
      "Wall time: 3min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "residential_filter = {\"building\": [\"residential\", \"apartments\", \"flats\", \"house\", \"yes\"]}\n",
    "residential_buildings = osm.get_buildings(custom_filter=residential_filter)\n",
    "residential_buildings = residential_buildings[['building', 'geometry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crudely get all places that might be considered workplaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.1 s, sys: 2.67 s, total: 25.8 s\n",
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pois_filter = {\"shop\": True,\"amenity\": True, \"leisure\": True, \"tourism\": True}\n",
    "pois_filter = {\"shop\": True,\"amenity\": True}\n",
    "pois = osm.get_pois(custom_filter=pois_filter)\n",
    "\n",
    "office_filter = {\"office\": True}\n",
    "offices = osm.get_data_by_custom_criteria(custom_filter=office_filter)\n",
    "\n",
    "office_building_filter = {\"building\": [\"office\", \"offices\"]}\n",
    "office_buildings = osm.get_buildings(custom_filter=office_building_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Combine the locations of all of the crude workplaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.53 s, sys: 62.5 ms, total: 2.59 s\n",
      "Wall time: 2.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trimmed_work = pois[['geometry']].copy()\n",
    "trimmed_work = trimmed_work.append(offices[['geometry']]).append(office_buildings[['geometry']])\n",
    "trimmed_work = trimmed_work.reset_index()\n",
    "orig_crs = trimmed_work.crs\n",
    "trimmed_work = trimmed_work.to_crs(OUT_CRS) # convert CRS to the final CRS for more correct centroids\n",
    "trimmed_work['geometry'] = trimmed_work.geometry.convex_hull.centroid  # we use the convex hull because otherwise we get wildly incorrect points for non-convex polygons results\n",
    "trimmed_work = trimmed_work.to_crs(orig_crs) # convert back for now\n",
    "# trimmed_work.plot(markersize=0.1)\n",
    "del pois, offices, office_buildings,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Acquire Population Count for Selected Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "# this can probably be replaced with an API call (https://www.worldpop.org/sdi/introapi) but isn't currently implemented \n",
    "uk_wp = rxr.open_rasterio('../data/gbr_ppp_2020_UNadj_constrained.tif', masked=True).squeeze() # acquired from https://www.worldpop.org/geodata/summary?id=29480\n",
    "print(uk_wp.rio.crs)  # make sure the crs is EPSG:4326 (WGS84) to match the unprojected OSM boundary\n",
    "wp_clipped = uk_wp.rio.clip(boundary.geometry.apply(mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load, Clip, and Transform Public Transit Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.33 s, sys: 62.5 ms, total: 3.39 s\n",
      "Wall time: 3.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "in_crs = \"EPSG:4326\"\n",
    "# get all public transport\n",
    "full_edges = pd.read_csv('../data/uk_aggregate/Data_Release_v1.11/edges.csv')\n",
    "full_nodes = pd.read_csv('../data/uk_aggregate/Data_Release_v1.11/nodes.csv')\n",
    "full_nodes = geopandas.GeoDataFrame(full_nodes, geometry=geopandas.points_from_xy(full_nodes.lon, full_nodes.lat), crs=in_crs)\n",
    "layers = pd.read_csv('../data/uk_aggregate/Data_Release_v1.11/layers.csv')\n",
    "\n",
    "# Clip the nodes to the boundary\n",
    "nodes = geopandas.clip(full_nodes, boundary)\n",
    "# Only select edges that start or end at the clipped nodes\n",
    "des_edges = full_edges[full_edges.rename(columns={'des_node': 'node', 'des_layer': 'layer'}).set_index(['node', 'layer']).index.isin(nodes.set_index(['node', 'layer']).index)]\n",
    "ori_edges = full_edges[full_edges.rename(columns={'ori_node': 'node', 'ori_layer': 'layer'}).set_index(['node', 'layer']).index.isin(nodes.set_index(['node', 'layer']).index)]\n",
    "edges = des_edges.merge(ori_edges) # inner merge to get edges that start and end in the boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up columns needed to be parsed by OSMNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes['osmid'] = nodes['node'].astype(str) + '_' + nodes['layer'].astype(str)\n",
    "nodes['x'] = nodes.geometry.x\n",
    "nodes['y'] = nodes.geometry.y\n",
    "nodes.set_index('osmid', verify_integrity=True, inplace=True, drop=False) # keep the column as osmnx needs it (as well as it being the index of the DF)\n",
    "\n",
    "edges['u'] = edges['ori_node'].astype(str) + '_' + edges['ori_layer'].astype(str)\n",
    "edges['v'] = edges['des_node'].astype(str) + '_' + edges['des_layer'].astype(str)\n",
    "edges['key'] = edges.reset_index()['index']\n",
    "edges['osmid'] = edges['u'].astype(str) + '_' + edges['v'].astype(str)\n",
    "edges.set_index(['u', 'v', 'key'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Line Geometries for the Edges to convert to GDDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.92 s, sys: 15.6 ms, total: 9.94 s\n",
      "Wall time: 9.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "old_index = full_nodes.index\n",
    "full_nodes = full_nodes.set_index(['node', 'layer'])\n",
    "edges = geopandas.GeoDataFrame(edges, geometry=edges.apply(lambda x: LineString([\n",
    "    full_nodes.loc[(x.ori_node, x.ori_layer)].geometry, \n",
    "    full_nodes.loc[(x.des_node, x.des_layer)].geometry\n",
    "]), axis=1))\n",
    "full_nodes = full_nodes.reset_index()\n",
    "full_nodes.index = old_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parse as OSMNX Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = osmnx.utils_graph.graph_from_gdfs(nodes, edges, None)\n",
    "graph_node_ids = osmnx.utils_graph.graph_to_gdfs(graph, edges=False).osmid # the graph module removes some nodes (probably unconnected ones, TODO investigate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise Collected Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05) # rescale the color bar to match the image\n",
    "wp_clipped.plot(ax=ax, cbar_kwargs={'cax': cax})\n",
    "osmnx.plot_graph(graph, ax=ax, node_size=5, node_color='orange', edge_linewidth=1, edge_color='orange')\n",
    "residential_buildings.plot(ax=ax, facecolor='none', edgecolor='r')\n",
    "trimmed_work.plot(ax=ax, markersize=1)\n",
    "print(f\"Total Population: {int(wp_clipped.sum())}\")\n",
    "print(f\"Buildings from OSM, Residential: {len(residential_buildings)}, Workplaces: {len(trimmed_work)}\")\n",
    "del fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Setup some Distributions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_boundary = boundary.copy().set_crs(\"EPSG:4326\").to_crs(OUT_CRS)\n",
    "bounds = projected_boundary.bounds\n",
    "(boundary_minx, boundary_maxx, boundary_miny, boundary_maxy)  = (bounds.loc[bounds.index[0], 'minx'], bounds.loc[bounds.index[0], 'maxx'], bounds.loc[bounds.index[0], 'miny'], bounds.loc[bounds.index[0], 'maxy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by https://gis.stackexchange.com/a/301935\n",
    "def cKDQueryRadius(gdA_in, gdB_in, radius=300, reproject=True, p=2.0, workers=1):\n",
    "    gdA = gdA_in.copy()\n",
    "    gdB = gdB_in.copy()\n",
    "    if reproject:\n",
    "        in_crs = gdA.crs\n",
    "        gdA = gdA.to_crs(OUT_CRS)\n",
    "        gdB = gdB.to_crs(OUT_CRS)\n",
    "        \n",
    "    nA = np.array(list(gdA.geometry.centroid.apply(lambda x: (x.x, x.y))))\n",
    "    nB = np.array(list(gdB.geometry.centroid.apply(lambda x: (x.x, x.y))))\n",
    "    \n",
    "    btree = cKDTree(nB)\n",
    "    elements_in_radius = btree.query_ball_point(nA, r=radius, p=p, workers=workers)\n",
    "\n",
    "    gdf = pd.concat(\n",
    "        [gdA.reset_index(drop=True),\n",
    "        pd.Series(elements_in_radius, name='Elements in Radius')], axis=1\n",
    "    )\n",
    "    if reproject:\n",
    "        gdf = gdf.to_crs(gdA_in.crs)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 1.53 s, total: 1min 6s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nx, ny = wp_clipped.sizes['x'], wp_clipped.sizes['y']\n",
    "x, y = wp_clipped.rio.transform() * np.meshgrid(np.arange(nx)+0.5, np.arange(ny)+0.5)\n",
    "\n",
    "# GeoDataFrame of centres of raster cells, indexed by their respective ravelled index\n",
    "raster_coords = geopandas.GeoDataFrame({'ravelled_index': np.arange(x.size)}, geometry=geopandas.points_from_xy(x.ravel(), y.ravel()), crs=\"EPSG:4326\")\n",
    "residences_in_radius = cKDQueryRadius(raster_coords, residential_buildings)\n",
    "del nx, ny, x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Household Size Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial values pretty much completely guessed, should be built off census data\n",
    "lower, upper = 1, 8\n",
    "mu, sigma = 2.2, 0.98\n",
    "\n",
    "household_size_dist = stats.truncnorm((lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.hist(household_size_dist.rvs(100_000).astype(int), density=True, bins=40)\n",
    "plt.show()\n",
    "del fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Workplace Size Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired from https://www.nature.com/articles/nature04795 supplementary information\n",
    "def workplace_size_truncated_power_law(m_max, a, c):\n",
    "    m = np.arange(1, m_max + 1, dtype='float')\n",
    "    pmf = (\n",
    "            (\n",
    "                    (\n",
    "                            ((1 + (m_max / a))\n",
    "                             /\n",
    "                             (1 + (m / a)))\n",
    "                            ** c)\n",
    "                    - 1)\n",
    "            /\n",
    "            ((\n",
    "                    ((1 + (m_max / a)) ** c)\n",
    "                    - 1)))\n",
    "    pmf /= pmf.sum()\n",
    "\n",
    "    return stats.rv_discrete(values=(range(1, m_max + 1), pmf))\n",
    "\n",
    "max_size = 5920\n",
    "workplace_size_dist = workplace_size_truncated_power_law(m_max=max_size, a=5.36, c=1.34)\n",
    "\n",
    "x = np.arange(1, max_size + 1)\n",
    "fig, ax = plt.subplots()\n",
    "y_pdf = workplace_size_dist.pmf(x)\n",
    "y_cdf = workplace_size_dist.cdf(x)\n",
    "ax.set_xscale(value=\"log\")\n",
    "ax.set_yscale(value=\"log\")\n",
    "ax.plot(x, y_pdf, label='pdf')\n",
    "ax.plot(x, y_cdf, label='cdf')\n",
    "ax.legend()\n",
    "del x, fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person():\n",
    "    def __init__(self, uid, household_uid, age, pos):\n",
    "        self.uid = uid\n",
    "        self.household_uid = household_uid\n",
    "        self.age = age\n",
    "        self.pos = pos\n",
    "        \n",
    "\n",
    "people = []\n",
    "\n",
    "def add_new_person(household_uid, pos):\n",
    "    age = random.randint(0, 108)  # Todo update this\n",
    "    \n",
    "    new_person = Person(uid=len(people), household_uid=household_uid, age=age, pos=pos)\n",
    "    people.append(new_person)\n",
    "    \n",
    "    return new_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Household():\n",
    "    def __init__(self, uid, max_inhabitants, pos: Tuple[float, float]):\n",
    "        self.uid = uid\n",
    "        self.inhabitants = 0\n",
    "        self.max_inhabitants = max_inhabitants\n",
    "        self.pos = pos\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'uid': self.uid,\n",
    "            'inhabitants': self.inhabitants,\n",
    "            'max_inhabitants': self.max_inhabitants,\n",
    "            'pos': self.pos,\n",
    "        }\n",
    "    \n",
    "households = []\n",
    "\n",
    "def add_new_household(pos_geometry):\n",
    "    max_inhabitants = household_size_dist.rvs(1)[0]\n",
    "    \n",
    "    new_household = Household(uid=len(households), max_inhabitants=max_inhabitants, pos=pos_geometry)\n",
    "    households.append(new_household)\n",
    "    \n",
    "    return new_household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidenceType(IntEnum):\n",
    "    HOUSE = 0\n",
    "    SMALL_FLATS = 1  # Perhaps a few floors or flats in one building\n",
    "    LARGE_FLATS = 2  # Generally high-rise, shared lifts, etc.\n",
    "\n",
    "\n",
    "# Again basically random numbers, need to be brought in from Census\n",
    "residence_params = {\n",
    "    'max_household_capacity': 7,\n",
    "    ResidenceType.HOUSE: {\n",
    "        'max_households': 2\n",
    "    },\n",
    "    ResidenceType.SMALL_FLATS: {\n",
    "        'max_households': 10\n",
    "    },\n",
    "    ResidenceType.LARGE_FLATS: {\n",
    "        'max_households': 150\n",
    "    }\n",
    "}\n",
    "\n",
    "residential_buildings['residence_type'] = ResidenceType.HOUSE\n",
    "residential_buildings.loc[residential_buildings['building'].isin(['apartments', 'flats']), 'residence_type'] = ResidenceType.SMALL_FLATS\n",
    "residential_buildings.drop('building', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Person Generation and Household Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "residences_to_households = defaultdict(lambda: [])\n",
    "residential_buildings = residential_buildings.to_crs(OUT_CRS)\n",
    "\n",
    "# reset lists\n",
    "households = []\n",
    "people = []\n",
    "failures = 0\n",
    "\n",
    "# for each tile of population\n",
    "for row in range(wp_clipped.shape[0]):\n",
    "    for col in range(wp_clipped.shape[1]):\n",
    "        index = (row, col)\n",
    "        people_at_tile = wp_clipped[row, col]\n",
    "        \n",
    "        if np.isnan(people_at_tile):\n",
    "            continue\n",
    "        \n",
    "        # residences near the center of the tile\n",
    "        local_residences_indices = residences_in_radius.loc[np.ravel_multi_index(index, wp_clipped.shape), 'Elements in Radius']\n",
    "        \n",
    "        for _ in range(int(people_at_tile)):\n",
    "            shuffled_indices = np.random.permutation(local_residences_indices)\n",
    "\n",
    "            chosen_household = None\n",
    "\n",
    "            for residence_index in shuffled_indices:\n",
    "                households_at_residence = [households[household_uid] for household_uid in residences_to_households[residence_index]]\n",
    "                possible_households = [household for household in households_at_residence if household.inhabitants < household.max_inhabitants]\n",
    "\n",
    "                if len(possible_households) != 0:\n",
    "                    chosen_household = random.choice(possible_households)\n",
    "                    chosen_household.inhabitants += 1\n",
    "                    break\n",
    "                else:\n",
    "                    building_type = residential_buildings.loc[residence_index, 'residence_type']\n",
    "                    \n",
    "                    if len(households_at_residence) < residence_params[building_type]['max_households']:\n",
    "                        pos = residential_buildings.loc[residence_index].geometry.centroid\n",
    "                        pos = (pos.x, pos.y)\n",
    "                        chosen_household = add_new_household(pos)\n",
    "                        residences_to_households[residence_index].append(chosen_household.uid)\n",
    "                        \n",
    "                        chosen_household.inhabitants += 1\n",
    "                        \n",
    "            else:  # failed to find an available household, or residence to make a new household in, so upgrade a residence \n",
    "                smaller_residences_indices = [residence_index for residence_index in local_residences_indices \n",
    "                                              if residential_buildings.loc[residence_index, 'residence_type'] != ResidenceType.LARGE_FLATS]\n",
    "                \n",
    "                if len(smaller_residences_indices) != 0:\n",
    "                    chosen_residence_index = random.choice(smaller_residences_indices)\n",
    "                    residential_buildings.loc[chosen_residence_index, 'residence_type'] = ResidenceType(residential_buildings.loc[chosen_residence_index, 'residence_type'] + 1)\n",
    "                    \n",
    "                    pos = residential_buildings.loc[chosen_residence_index].geometry.centroid\n",
    "                    pos = (pos.x, pos.y)\n",
    "                    chosen_household = add_new_household(pos)\n",
    "                    residences_to_households[chosen_residence_index].append(chosen_household.uid)\n",
    "                else:\n",
    "                        failures += 1\n",
    "                        continue\n",
    "#                     raise Exception(\"Bugger gotta deal with this\")\n",
    "            add_new_person(chosen_household.uid, chosen_household.pos)    \n",
    "print(f\"Failures: {failures}/{int(wp_clipped.sum())}, Failure Rate: {failures/int(wp_clipped.sum()):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workplace Selection and Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate workplace capacities\n",
    "trimmed_work['capacity'] = workplace_size_dist.rvs(size=len(trimmed_work))\n",
    "# reproject workplaces\n",
    "trimmed_work = trimmed_work.to_crs(OUT_CRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df = pd.DataFrame(data=[{'uid': person.uid, 'x': person.pos[0], 'y': person.pos[1], 'age': person.age} for person in people])\n",
    "del people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_size = 50 # meters for OUT_CRS\n",
    "y_len = int(math.ceil((boundary_maxy - boundary_miny) / bucket_size))\n",
    "x_len = int(math.ceil((boundary_maxx - boundary_minx) / bucket_size))\n",
    "\n",
    "print(f'y: {y_len}, x: {x_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployed = people_df.loc[(17 <= people_df['age']) & (people_df['age'] <= 67)].copy()\n",
    "print(len(unemployed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployed['bucket_x'] = np.ceil(((unemployed['x'] - boundary_minx) / bucket_size)).astype(int) - 1\n",
    "unemployed['bucket_y'] = np.ceil(y_len - ((unemployed['y'] - boundary_miny) / bucket_size)).astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_buckets():\n",
    "    unemployed_bucket = [[[] for x in range(x_len)] for y in range(y_len)]\n",
    "    for person in unemployed.itertuples():\n",
    "        unemployed_bucket[person.bucket_y][person.bucket_x].append(person.uid)\n",
    "    \n",
    "    return unemployed_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "unemployed_bucket = make_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/44865023/how-can-i-create-a-circular-mask-for-a-numpy-array\n",
    "def create_circular_mask(h, w, centre_y=None, centre_x=None, radius=None):\n",
    "    if centre_x is None: # use the middle of the image\n",
    "        centre_x = int(w / 2)\n",
    "    if centre_y is None:\n",
    "        centre_y = int(h / 2)\n",
    "    if radius is None: # use the smallest distance between the center and image walls\n",
    "        radius = min(centre_y, centre_x, (w - centre_x), (h - centre_y))\n",
    "\n",
    "    y, x = np.ogrid[-centre_y:(h - centre_y), -centre_x:(w - centre_x)]\n",
    "    mask = (x * x) + (y * y) <= (radius * radius)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoViablePeopleError(Exception):\n",
    "    pass\n",
    "\n",
    "# A generator that takes a center point and a radius, and efficiently finds an unemployed person in that radius \n",
    "def valid_unemployed_within_dist(y, x, dist, cache_size=200):\n",
    "    counts = np.array([list(map(len, row)) for row in unemployed_bucket])\n",
    "    y = y_len - int(math.ceil((y - boundary_miny) / bucket_size)) - 1\n",
    "    x = int(math.ceil((x - boundary_minx) / bucket_size)) - 1\n",
    "    dist = dist / bucket_size\n",
    "    mask = create_circular_mask(h=y_len, w=x_len, centre_y=y, centre_x=x, radius=dist)\n",
    "    \n",
    "    indices = np.argwhere(mask)\n",
    "    if np.sum(counts[mask]) == 0:\n",
    "        raise NoViablePeopleError(f'No viable unemployed people left around (x:{x}, y:{y})')\n",
    "    probabilities = counts[mask] / np.sum(counts[mask])\n",
    "    \n",
    "    chosen_buckets = np.random.choice(np.arange(indices.shape[0]), cache_size, p=probabilities) # a cache of sampled choices\n",
    "    chosen_iter = iter(chosen_buckets)\n",
    "    failures = 0\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            next_bucket_pos = tuple(indices[next(chosen_iter)])\n",
    "        except StopIteration: # used up the cache, repopulate with some more random choices\n",
    "            chosen_buckets = np.random.choice(np.arange(indices.shape[0]), cache_size, p=probabilities)\n",
    "            chosen_iter = iter(chosen_buckets)\n",
    "            continue\n",
    "        try: \n",
    "            next_person = unemployed_bucket[next_bucket_pos[0]][next_bucket_pos[1]].pop()\n",
    "        except IndexError: # no unemployed people in that bucket\n",
    "            failures += 1\n",
    "            if failures > 300: # we had a lot of failures, recalc the probability map\n",
    "                failures = 0\n",
    "                \n",
    "                counts = np.array([list(map(len, row)) for row in unemployed_bucket])\n",
    "                \n",
    "                total_unemployed_left = np.sum(counts[mask])\n",
    "                if total_unemployed_left == 0:\n",
    "                    raise NoViablePeopleError(f'No viable unemployed people left around ({x}, {y})')\n",
    "                \n",
    "                probabilities = counts[mask] / total_unemployed_left\n",
    "                \n",
    "                chosen_buckets = np.random.choice(np.arange(indices.shape[0]), cache_size, p=probabilities)\n",
    "                chosen_iter = iter(chosen_buckets)\n",
    "            continue\n",
    "            \n",
    "        yield next_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class TransportType(Enum):\n",
    "    DRIVING = 0,\n",
    "    CYCLING = 1,\n",
    "    WALKING = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "to_allocate = len(unemployed)\n",
    "print(f'Trying to allocate {to_allocate} people, {len(trimmed_work)} workplaces')\n",
    "\n",
    "unemployed_bucket = make_buckets()\n",
    "\n",
    "people_to_workplaces = [None] * len(people_df)\n",
    "people_to_transport_type = [None] * len(people_df)\n",
    "\n",
    "failures = 0\n",
    "successes = 0\n",
    "workplace_indices = []\n",
    "\n",
    "for index, workplace in enumerate(trimmed_work.sample(frac=1).itertuples()): # iterate over shuffled workplaces\n",
    "    if successes >= to_allocate:\n",
    "        print(f'Allocated all people after {index} workplaces')\n",
    "        break\n",
    "    if index < 9:\n",
    "        workplace_indices.append(workplace.index) # hacky way to select some workplaces for analysis later on\n",
    "        \n",
    "    transport_options = [TransportType.DRIVING, TransportType.CYCLING, TransportType.WALKING]\n",
    "    \n",
    "    valid_unemployed_gen_60k = valid_unemployed_within_dist(workplace.geometry.y, workplace.geometry.x, 60_000)\n",
    "    valid_unemployed_gen_20k = valid_unemployed_within_dist(workplace.geometry.y, workplace.geometry.x, 20_000)\n",
    "    valid_unemployed_gen_5k = valid_unemployed_within_dist(workplace.geometry.y, workplace.geometry.x, 5_000)\n",
    "    \n",
    "    for _ in range(workplace.capacity):\n",
    "        # TODO update to better reflect real distributions if possible, maybe weight it by workplace size, more likely to walk if you own the business\n",
    "        random.shuffle(transport_options)\n",
    "        random_transport = iter(transport_options)\n",
    "        \n",
    "        person_id = None\n",
    "        transport_type = None\n",
    "        \n",
    "        while (person_id == None):\n",
    "            try:\n",
    "                transport_type = next(random_transport)\n",
    "            except StopIteration:\n",
    "                break\n",
    "            if transport_type == TransportType.DRIVING:\n",
    "                try:\n",
    "                    person_id = next(valid_unemployed_gen_60k)\n",
    "                except NoViablePeopleError:\n",
    "                    transport_options.remove(transport_type)\n",
    "            elif transport_type == TransportType.CYCLING:\n",
    "                try:\n",
    "                    person_id = next(valid_unemployed_gen_20k)\n",
    "                except NoViablePeopleError:\n",
    "                    transport_options.remove(transport_type)\n",
    "            elif transport_type == TransportType.WALKING:\n",
    "                try:\n",
    "                    person_id = next(valid_unemployed_gen_5k)\n",
    "                except NoViablePeopleError:\n",
    "                    transport_options.remove(transport_type)\n",
    "        \n",
    "        if person_id:\n",
    "            if transport_type:\n",
    "                people_to_transport_type[person_id] = transport_type\n",
    "            \n",
    "            people_to_workplaces[person_id] = workplace.index\n",
    "            successes += 1\n",
    "            if successes >= to_allocate:\n",
    "                break\n",
    "        else:\n",
    "            failures +=1\n",
    "            continue            \n",
    "    \n",
    "    # workplace_row.capacity\n",
    "    # workplace.index    \n",
    "    \n",
    "print(f'Successes: {successes}, Failures: {failures}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workplaces_to_people = defaultdict(list)\n",
    "for person_id, workplace_index in enumerate(people_to_workplaces):\n",
    "    if workplace_index is not None:\n",
    "        workplaces_to_people[workplace_index].append(person_id)\n",
    "\n",
    "example_workplaces_to_people = {ind: workplaces_to_people[ind] for ind in workplace_indices}\n",
    "        \n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "ax.set_aspect('equal')\n",
    "marker_styles = [\n",
    "                ('red', 'o'), ('blue', 'o'), ('green', 'o'),\n",
    "                ('red', 'P'), ('blue', 'P'), ('green', 'P'),\n",
    "                ('red', '*'), ('blue', '*'), ('green', '*')\n",
    "                ]\n",
    "\n",
    "for (workplace_index, worker_indices), (color, marker) in zip(example_workplaces_to_people.items(), marker_styles):\n",
    "    trimmed_work.iloc[[workplace_index]].plot(ax=ax, markersize=100, c=color, marker=marker)\n",
    "    workers = people_df.iloc[worker_indices]\n",
    "    workers.plot(ax=ax, x='x', y='y', kind='scatter', s=30, c=color, marker=marker)\n",
    "del fig, ax, workplaces_to_people"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
